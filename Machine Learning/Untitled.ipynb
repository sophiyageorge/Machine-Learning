{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dcfc3fb",
   "metadata": {},
   "source": [
    " Logistic Regression\n",
    " \n",
    " Logistic Regression is a supervised machine learning algorithm used for classification tasks â€” most commonly binary classification.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d15bcb",
   "metadata": {},
   "source": [
    "Logistic regression predicts the probability that a given input belongs to a particular class, usually 0 or 1 (e.g., No or Yes, Negative or Positive).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba60678",
   "metadata": {},
   "source": [
    "Python Code From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97740afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Loss: 0.6931\n",
      "Epoch 100 - Loss: 0.4680\n",
      "Epoch 200 - Loss: 0.3649\n",
      "Epoch 300 - Loss: 0.3062\n",
      "Epoch 400 - Loss: 0.2680\n",
      "Epoch 500 - Loss: 0.2410\n",
      "Epoch 600 - Loss: 0.2207\n",
      "Epoch 700 - Loss: 0.2047\n",
      "Epoch 800 - Loss: 0.1916\n",
      "Epoch 900 - Loss: 0.1807\n",
      "\n",
      "Final weight and bias:\n",
      "w = 1.769045864973106\n",
      "b = -5.956350539118638\n",
      "\n",
      "If a student studies 3.5 hours, will they pass? Yes\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Step 1: Input data\n",
    "X = np.array([1, 2, 3, 4, 5])\n",
    "Y = np.array([0, 0, 0, 1, 1])\n",
    "\n",
    "# Step 2: Initialize weights and bias\n",
    "w = 0.0\n",
    "b = 0.0\n",
    "\n",
    "# Sigmoid function\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Step 3: Train the model using Gradient Descent\n",
    "learning_rate = 0.1\n",
    "epochs = 1000\n",
    "\n",
    "m = len(X)  # number of samples\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    z = w * X + b\n",
    "    y_pred = sigmoid(z)\n",
    "\n",
    "    # Binary Cross Entropy Loss\n",
    "    loss = -np.mean(Y * np.log(y_pred) + (1 - Y) * np.log(1 - y_pred))\n",
    "\n",
    "    # Gradients\n",
    "    dw = np.dot((y_pred - Y), X) / m\n",
    "    db = np.sum(y_pred - Y) / m\n",
    "\n",
    "    # Update weights\n",
    "    w -= learning_rate * dw\n",
    "    b -= learning_rate * db\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch} - Loss: {loss:.4f}\")\n",
    "\n",
    "# Final weights\n",
    "print(\"\\nFinal weight and bias:\")\n",
    "print(\"w =\", w)\n",
    "print(\"b =\", b)\n",
    "\n",
    "# Step 4: Prediction\n",
    "def predict(x):\n",
    "    z = w * x + b\n",
    "    prob = sigmoid(z)\n",
    "    return 1 if prob >= 0.5 else 0\n",
    "\n",
    "# Test prediction\n",
    "test_hours = 3.5\n",
    "result = predict(test_hours)\n",
    "print(f\"\\nIf a student studies {test_hours} hours, will they pass? {'Yes' if result == 1 else 'No'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9098a153",
   "metadata": {},
   "source": [
    "Implementation with Python (using scikit-learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f146c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.956140350877193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load data\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
